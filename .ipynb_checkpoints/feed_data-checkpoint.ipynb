{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import PsiMarginal_fd\n",
    "import datetime\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_merged_data(TEMP):\n",
    "    \n",
    "    if TEMP == False:\n",
    "        FID = input('add file ID:')\n",
    "    else:\n",
    "        FID = \"TEMP\"\n",
    "\n",
    "    global file_path_TEMP\n",
    "    global timestamp\n",
    "\n",
    "    timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H-%M')\n",
    "    file_name_data = FID +\"_\"+ bs + \"_\" + hv +\"_data_\"+ timestamp +\".npy\"\n",
    "\n",
    "    file_name_stim = FID +\"_\"+ bs + \"_\" + hv +\"_stim_\"+ timestamp +\".npy\"\n",
    "    file_name_response = FID +\"_\"+ bs + \"_\" + hv +\"_response_\"+ timestamp +\".npy\"\n",
    "    file_name_postmean = FID +\"_\"+ bs + \"_\" + hv +\"_postmean_\"+ timestamp +\".npy\"\n",
    "    file_name_poststd = FID +\"_\"+ bs + \"_\" + hv +\"_poststd_\"+ timestamp +\".npy\"\n",
    "    file_name_stimRange = FID +\"_\"+ bs + \"_\" + hv +\"_stimRange_\"+ timestamp +\".npy\"\n",
    "\n",
    "    file_name_pThreshold = FID +\"_\"+ bs + \"_\" + hv +\"_pThreshold_\"+ timestamp +\".npy\"\n",
    "    file_name_pSlope = FID +\"_\"+ bs + \"_\" + hv +\"_pSlope_\"+ timestamp +\".npy\"\n",
    "    file_name_pLapse = FID +\"_\"+ bs + \"_\" + hv +\"_pLapse_\"+ timestamp +\".npy\"\n",
    "    file_name_pGuess = FID +\"_\"+ bs + \"_\" + hv +\"_pGuess_\"+ timestamp +\".npy\"\n",
    "    file_name_eThreshold = FID +\"_\"+ bs + \"_\" + hv +\"_eThreshold_\"+ timestamp +\".npy\"\n",
    "    file_name_eSlope = FID +\"_\"+ bs + \"_\" + hv +\"_eSlope_\"+ timestamp +\".npy\"\n",
    "    file_name_eLapse = FID +\"_\"+ bs + \"_\" + hv +\"_eLapse_\"+ timestamp +\".npy\"\n",
    "    file_name_eGuess = FID +\"_\"+ bs + \"_\" + hv +\"_eGuess_\"+ timestamp +\".npy\"\n",
    "    file_name_stdThreshold = FID +\"_\"+ bs + \"_\" + hv +\"_stdThreshold_\"+ timestamp +\".npy\"\n",
    "    file_name_stdSlope = FID +\"_\"+ bs + \"_\" + hv +\"_stdSlope_\"+ timestamp +\".npy\"\n",
    "    file_name_stdLapse = FID +\"_\"+ bs + \"_\" + hv +\"_stdLapse_\"+ timestamp +\".npy\"\n",
    "    file_name_stdGuess = FID +\"_\"+ bs + \"_\" + hv +\"_stdGuess_\"+ timestamp +\".npy\"\n",
    "\n",
    "    file_path_TEMP = os.path.join(glob.glob('C:\\\\Users\\\\mvomstein\\\\projects\\\\vt_2pod_data_analysis')[0],\n",
    "                                  'DATA_merged', FID)\n",
    "\n",
    "    #check for directory with TSID\n",
    "    if not os.path.isdir(file_path_TEMP):\n",
    "        os.mkdir(file_path_TEMP)\n",
    "        print(\"new directory \" + FID + \" created\")\n",
    "\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_stim), psi.stim)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_response), psi.response)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_postmean), psi.postmean)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_poststd), psi.poststd)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_stimRange), psi.stimRange)\n",
    "        \n",
    "    np.save(os.path.join(file_path_TEMP, file_name_pThreshold), psi.pThreshold)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_pSlope), psi.pSlope)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_pLapse), psi.pLapse)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_pGuess), psi.pGuess)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_eThreshold), psi.eThreshold)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_eSlope), psi.eSlope)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_eLapse), psi.eLapse)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_eGuess), psi.eGuess)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_stdThreshold), psi.stdThreshold)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_stdSlope), psi.stdSlope)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_stdLapse), psi.stdLapse)\n",
    "    np.save(os.path.join(file_path_TEMP, file_name_stdGuess), psi.stdGuess)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSIDs:\n",
    "\n",
    "TSIDs = ['TEST-HOP', 'TEST-VST', 'TEST-SOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data File Path:\n",
    "\n",
    "file_path = os.path.join(glob.glob('C:\\\\Users\\\\mvomstein\\\\projects\\\\vt-2pod-master')[0], 'DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allocate Data in Variables:\n",
    "\n",
    "for TSID in TSIDs:\n",
    "    fpTS = os.path.join(file_path, TSID)\n",
    "\n",
    "    for file in os.listdir(fpTS):\n",
    "        if os.path.splitext(file)[1] == '.npy':\n",
    "            x = re.split(\"_\", file)\n",
    "            if \"user\" in x:\n",
    "                del x[x.index(\"user\")]\n",
    "            globals()[x[0] + \"_\" + x[1] + \"_\" + x[2] + \"_\" + x[3]] = np.load(os.path.join(fpTS, file), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data:\n",
    "\n",
    "bs = 'back-lower'\n",
    "hv = 'v'\n",
    "\n",
    "stim = np.array([])\n",
    "resp = np.array([])\n",
    "\n",
    "for TSID in TSIDs:\n",
    "    stim = np.append(stim, globals()[TSID+'_'+bs+'_'+hv+'_stim'])\n",
    "    resp = np.append(resp, globals()[TSID+'_'+bs+'_'+hv+'_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = len(stim)  # number of trials\n",
    "a = np.linspace(0.01, 60, 31)  # threshold/bias grid\n",
    "b = np.linspace(0.01, 10, 50)  # slope grid\n",
    "x = globals()[TSID+'_'+bs+'_'+hv+'_stimRange']  # possible stimuli to use\n",
    "delta = 0.02  # lapse\n",
    "gamma = np.linspace(0.01, 0.99, 100) # guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_X = stim[0]\n",
    "\n",
    "# initialize algorithm\n",
    "psi = PsiMarginal_fd.Psi(x, Pfunction='Weibull', nTrials=ntrials, threshold=a, slope=b, guessRate=gamma,\n",
    "                      lapseRate=delta, marginalize=False, init_x=INIT_X)\n",
    "\n",
    "\n",
    "for i in range(0, ntrials):  # run for length of trials\n",
    "    print ('\\rTrial %d of %d' % (i+1, ntrials), end='')\n",
    "\n",
    "    data_r = resp[i]\n",
    "    if i<len(stim)-1: data_x = stim[i+1]\n",
    "    psi.addData(data_r, data_x)  # update Psi with response\n",
    "    while psi.xCurrent == None:  # wait until next stimuli is calculated\n",
    "        pass\n",
    "\n",
    "psi.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP = True\n",
    "\n",
    "save_merged_data(TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEMP:\n",
    "    shutil.rmtree(file_path_TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
