{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b5327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import itertools\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "xr.set_options(display_expand_data=False)\n",
    "\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f8cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSIDs:\n",
    "TSIDs = ['BESI', 'GREGOR', 'HOP', 'JIL', 'NICHTJIL', 'SOM', \n",
    "         'TEST-HOP', 'TEST-HOP-mgn', 'TEST-SOM-mgn', 'TEST-VST',\n",
    "         'TS021', 'TS025', 'TS027', 'TS028', 'TS029', 'VST']\n",
    "\n",
    "#Data File Path:\n",
    "file_path = os.path.join(glob.glob('C:\\\\Users\\\\mvomstein\\\\projects\\\\vt-2pod')[0], 'DATA')\n",
    "\n",
    "file_path_save = glob.glob(\n",
    "    'C:\\\\Users\\\\mvomstein\\\\projects\\\\vt_2pod_data_analysis\\\\DATA_xr')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189c8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = np.loadtxt(os.path.join(file_path,'survey_2023-01-05.tsv'),\n",
    "                 delimiter=\"\\t\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64af1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "BSs = ['forearm', 'back-lower', 'back-lower-nsa', 'abdomen', 'thigh']\n",
    "HVs = ['h', 'v']\n",
    "\n",
    "bsDic = {'forearm': 0,\n",
    "         'back-lower': 1,\n",
    "         'back-lower-nsa': 2,\n",
    "         'abdomen': 3,\n",
    "         'thigh': 4}\n",
    "\n",
    "hvDic = {'h': 0,\n",
    "         'v': 1}\n",
    "\n",
    "sexDic = {'F': 0, 'M': 1}\n",
    "\n",
    "medicalDic = {0 : 'Keine',\n",
    "              1 : 'Diabetes',\n",
    "              2 : 'Kapaltunnel',\n",
    "              3 : 'Neurodermitis',\n",
    "              4 : 'Taktile Wahrnehmungsveraenderung',\n",
    "              5 : 'ADHS',\n",
    "              6 : 'Lernstoerung',\n",
    "              7 : 'Erkrankung ZNS',\n",
    "              8 : 'Beeintraechtigung Sehsinn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a421d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatch(param, fpts, bs, hv, datatype):\n",
    "    matches = [match for match in os.listdir(fpts) \n",
    "           if bs in match \n",
    "           and hv in match \n",
    "           and param in match\n",
    "           and os.path.splitext(match)[1] == datatype\n",
    "          ]\n",
    "    #print(matches)\n",
    "    if len(matches) >=2: raise Exception(f'MULTIPLE ENTRIES IN {TSID}: DATA NOT CLEAN', matches)\n",
    "    return(matches)\n",
    "\n",
    "def getTimestampFromStr(timestampStr):\n",
    "    timestamp = re.split(r'_|-', timestampStr)\n",
    "    timestamp = [int(i) for i in timestamp]\n",
    "    timestamp = datetime.datetime(timestamp[0], timestamp[1], timestamp[2], timestamp[3], timestamp[4], )\n",
    "    timestamp = time.mktime(timestamp.timetuple())\n",
    "    return(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc731497",
   "metadata": {},
   "outputs": [],
   "source": [
    "xStr = ['postmean', 'poststd', 'stim', 'response', 'pGuess', 'pSlope', 'pThresh']\n",
    "yVal = [np.arange(2.5, 61, 2.5),\n",
    "        np.arange(2.5, 61, 2.5),\n",
    "        np.arange(0, 50, 1),\n",
    "        np.arange(0, 50, 1),\n",
    "        np.linspace(0.01, 0.99, 100), #guess\n",
    "        np.linspace(0.01, 10, 50), #slope\n",
    "        np.linspace(0.01, 60, 31) #thresh\n",
    "       ]\n",
    "yStr = ['stimRange', 'stimRange', 'trial', 'trial', 'guessGrid', 'slopeGrid', 'threshGrid']\n",
    "\n",
    "for i in range(0, len(xStr), 1):\n",
    "    for TSID in TSIDs:\n",
    "        fpTS = os.path.join(file_path, TSID)\n",
    "        arr = np.random.normal(size=(len(yVal[i]),1,5,2))*np.nan\n",
    "        for BS, HV in itertools.product(BSs, HVs):\n",
    "            matches = getMatch('_'+xStr[i]+'_', fpTS, '_'+BS+'_', '_'+HV+'_', '.npy')\n",
    "            if matches:\n",
    "                x = re.split(\"_\", matches[0])\n",
    "                singleData =np.load(\n",
    "                    os.path.join(fpTS, matches[0]), allow_pickle=True)\n",
    "                arr[:len(singleData),0, bsDic[x[1]], hvDic[x[2]]] = singleData\n",
    "\n",
    "                #x[0]: TSID, x[1]: bs, x[2]: hv\n",
    "\n",
    "        da = xr.DataArray(\n",
    "            arr,\n",
    "            dims=[yStr[i], 'tsid', 'bs', 'hv'],\n",
    "            coords={yStr[i]:yVal[i],\n",
    "                    'tsid':[TSID], 'bs':BSs, 'hv':['h', 'v']},\n",
    "            name=xStr[i]\n",
    "        )\n",
    "        da.to_netcdf(os.path.join(file_path_save, xStr[i], xStr[i]+TSID+'.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fee09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eParams\n",
    "# =============================================================================\n",
    "\n",
    "yStr = ['eGuess', 'eLapse', 'eSlope', 'eThreshold', \n",
    "        'stdGuess', 'stdLapse', 'stdSlope', 'stdThreshold']\n",
    "\n",
    "for TSID in TSIDs:\n",
    "    fpTS = os.path.join(file_path, TSID)\n",
    "    arr = np.random.normal(size=(8,1,5,2))*np.nan\n",
    "    for BS, HV, i in itertools.product(BSs, HVs, range(0, len(yStr))):\n",
    "        matches = getMatch('_'+yStr[i]+'_', fpTS, '_'+BS+'_', '_'+HV+'_', '.npy')\n",
    "        if matches:\n",
    "            x = re.split(\"_\", matches[0])\n",
    "            singleData =np.load(\n",
    "                os.path.join(fpTS, matches[0]), allow_pickle=True)\n",
    "            arr[i ,0, bsDic[x[1]], hvDic[x[2]]] = singleData\n",
    "\n",
    "                #x[0]: TSID, x[1]: bs, x[2]: hv\n",
    "\n",
    "    da = xr.DataArray(\n",
    "        arr,\n",
    "        dims=['variableEP', 'tsid', 'bs', 'hv'],\n",
    "        coords={'variableEP':yStr,\n",
    "                'tsid':[TSID], 'bs':BSs, 'hv':['h', 'v']},\n",
    "        name='eParams'\n",
    "    )\n",
    "    da.to_netcdf(os.path.join(file_path_save, 'eParams', 'eParams'+TSID+'.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515396f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 23.  23.]\n",
      "   [ 23.  23.]\n",
      "   [ 23.  23.]\n",
      "   [ 23.  23.]\n",
      "   [ 23.  23.]]]\n",
      "\n",
      "\n",
      " [[[193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]]]\n",
      "\n",
      "\n",
      " [[[ 88.  88.]\n",
      "   [ 88.  88.]\n",
      "   [ 88.  88.]\n",
      "   [ 88.  88.]\n",
      "   [ 88.  88.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[  1.   1.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 38.  38.]\n",
      "   [ 38.  38.]\n",
      "   [ 38.  38.]\n",
      "   [ 38.  38.]\n",
      "   [ 38.  38.]]]\n",
      "\n",
      "\n",
      " [[[180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]]]\n",
      "\n",
      "\n",
      " [[[ 73.  73.]\n",
      "   [ 73.  73.]\n",
      "   [ 73.  73.]\n",
      "   [ 73.  73.]\n",
      "   [ 73.  73.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[  1.   1.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]]]\n",
      "\n",
      "\n",
      " [[[193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]]]\n",
      "\n",
      "\n",
      " [[[ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]]]\n",
      "\n",
      "\n",
      " [[[180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]]]\n",
      "\n",
      "\n",
      " [[[ 64.  64.]\n",
      "   [ 64.  64.]\n",
      "   [ 64.  64.]\n",
      "   [ 64.  64.]\n",
      "   [ 64.  64.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[  1.  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]]]\n",
      "\n",
      "\n",
      " [[[180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]]]\n",
      "\n",
      "\n",
      " [[[ 64.  64.]\n",
      "   [ 64.  64.]\n",
      "   [ 64.  64.]\n",
      "   [ 64.  64.]\n",
      "   [ 64.  64.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [  0.   1.]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]]]\n",
      "\n",
      "\n",
      " [[[185. 185.]\n",
      "   [185. 185.]\n",
      "   [185. 185.]\n",
      "   [185. 185.]\n",
      "   [185. 185.]]]\n",
      "\n",
      "\n",
      " [[[ 82.  82.]\n",
      "   [ 82.  82.]\n",
      "   [ 82.  82.]\n",
      "   [ 82.  82.]\n",
      "   [ 82.  82.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  1.   1.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]]]\n",
      "\n",
      "\n",
      " [[[193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]]]\n",
      "\n",
      "\n",
      " [[[ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.  nan]\n",
      "   [  1.   1.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[  1.  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]\n",
      "   [ 30.  30.]]]\n",
      "\n",
      "\n",
      " [[[193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]\n",
      "   [193. 193.]]]\n",
      "\n",
      "\n",
      " [[[ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]\n",
      "   [ 86.  86.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan   1.]\n",
      "   [  1.  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan   0.]\n",
      "   [  0.  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]]]\n",
      "\n",
      "\n",
      " [[[185. 185.]\n",
      "   [185. 185.]\n",
      "   [185. 185.]\n",
      "   [185. 185.]\n",
      "   [185. 185.]]]\n",
      "\n",
      "\n",
      " [[[ 82.  82.]\n",
      "   [ 82.  82.]\n",
      "   [ 82.  82.]\n",
      "   [ 82.  82.]\n",
      "   [ 82.  82.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 32.  32.]\n",
      "   [ 32.  32.]\n",
      "   [ 32.  32.]\n",
      "   [ 32.  32.]\n",
      "   [ 32.  32.]]]\n",
      "\n",
      "\n",
      " [[[190. 190.]\n",
      "   [190. 190.]\n",
      "   [190. 190.]\n",
      "   [190. 190.]\n",
      "   [190. 190.]]]\n",
      "\n",
      "\n",
      " [[[ 89.  89.]\n",
      "   [ 89.  89.]\n",
      "   [ 89.  89.]\n",
      "   [ 89.  89.]\n",
      "   [ 89.  89.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [  0.  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [  0.   1.]\n",
      "   [  1.  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ 21.  21.]\n",
      "   [ 21.  21.]\n",
      "   [ 21.  21.]\n",
      "   [ 21.  21.]\n",
      "   [ 21.  21.]]]\n",
      "\n",
      "\n",
      " [[[172. 172.]\n",
      "   [172. 172.]\n",
      "   [172. 172.]\n",
      "   [172. 172.]\n",
      "   [172. 172.]]]\n",
      "\n",
      "\n",
      " [[[ 65.  65.]\n",
      "   [ 65.  65.]\n",
      "   [ 65.  65.]\n",
      "   [ 65.  65.]\n",
      "   [ 65.  65.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan   0.]\n",
      "   [  0.  nan]\n",
      "   [ nan  nan]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan   0.]\n",
      "   [  0.  nan]\n",
      "   [ nan  nan]\n",
      "   [  0.   0.]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 25.  25.]\n",
      "   [ 25.  25.]\n",
      "   [ 25.  25.]\n",
      "   [ 25.  25.]\n",
      "   [ 25.  25.]]]\n",
      "\n",
      "\n",
      " [[[180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]\n",
      "   [180. 180.]]]\n",
      "\n",
      "\n",
      " [[[ 75.  75.]\n",
      "   [ 75.  75.]\n",
      "   [ 75.  75.]\n",
      "   [ 75.  75.]\n",
      "   [ 75.  75.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  1.   1.]\n",
      "   [ nan  nan]\n",
      "   [  1.   1.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]\n",
      "   [ 27.  27.]]]\n",
      "\n",
      "\n",
      " [[[187. 187.]\n",
      "   [187. 187.]\n",
      "   [187. 187.]\n",
      "   [187. 187.]\n",
      "   [187. 187.]]]\n",
      "\n",
      "\n",
      " [[[ 88.  88.]\n",
      "   [ 88.  88.]\n",
      "   [ 88.  88.]\n",
      "   [ 88.  88.]\n",
      "   [ 88.  88.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [ nan   1.]\n",
      "   [  1.  nan]\n",
      "   [  1.   1.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  1.   1.]\n",
      "   [ nan   0.]\n",
      "   [  1.  nan]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 28.  28.]\n",
      "   [ 28.  28.]\n",
      "   [ 28.  28.]\n",
      "   [ 28.  28.]\n",
      "   [ 28.  28.]]]\n",
      "\n",
      "\n",
      " [[[192. 192.]\n",
      "   [192. 192.]\n",
      "   [192. 192.]\n",
      "   [192. 192.]\n",
      "   [192. 192.]]]\n",
      "\n",
      "\n",
      " [[[ 80.  80.]\n",
      "   [ 80.  80.]\n",
      "   [ 80.  80.]\n",
      "   [ 80.  80.]\n",
      "   [ 80.  80.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  1.   1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]\n",
      "   [ 26.  26.]]]\n",
      "\n",
      "\n",
      " [[[174. 174.]\n",
      "   [174. 174.]\n",
      "   [174. 174.]\n",
      "   [174. 174.]\n",
      "   [174. 174.]]]\n",
      "\n",
      "\n",
      " [[[ 81.  81.]\n",
      "   [ 81.  81.]\n",
      "   [ 81.  81.]\n",
      "   [ 81.  81.]\n",
      "   [ 81.  81.]]]\n",
      "\n",
      "\n",
      " [[[  5.   5.]\n",
      "   [  5.   5.]\n",
      "   [  5.   5.]\n",
      "   [  5.   5.]\n",
      "   [  5.   5.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  1.   1.]\n",
      "   [ nan  nan]\n",
      "   [  2.   2.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[  1.   1.]\n",
      "   [  1.   0.]\n",
      "   [ nan  nan]\n",
      "   [  2.   2.]\n",
      "   [  1.   1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[[[  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]\n",
      "   [  1.   1.]]]\n",
      "\n",
      "\n",
      " [[[ 32.  32.]\n",
      "   [ 32.  32.]\n",
      "   [ 32.  32.]\n",
      "   [ 32.  32.]\n",
      "   [ 32.  32.]]]\n",
      "\n",
      "\n",
      " [[[190. 190.]\n",
      "   [190. 190.]\n",
      "   [190. 190.]\n",
      "   [190. 190.]\n",
      "   [190. 190.]]]\n",
      "\n",
      "\n",
      " [[[ 89.  89.]\n",
      "   [ 89.  89.]\n",
      "   [ 89.  89.]\n",
      "   [ 89.  89.]\n",
      "   [ 89.  89.]]]\n",
      "\n",
      "\n",
      " [[[  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  1.   1.]\n",
      "   [  0.   0.]]]\n",
      "\n",
      "\n",
      " [[[ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [ nan  nan]\n",
      "   [  1.   0.]\n",
      "   [  1.   1.]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tsMeta\n",
    "# =============================================================================\n",
    "\n",
    "yStr = ['sex', 'age', 'height', 'weight', 'medical', 'chonk', 'hair']\n",
    "\n",
    "sex_missing = []\n",
    "chonk_missing = []\n",
    "for TSID in TSIDs:\n",
    "    fpTS = os.path.join(file_path, TSID)\n",
    "    arr = np.random.normal(size=(len(yStr),1,5,2))*np.nan\n",
    "    \n",
    "    # sex, age, height, weight, sickness\n",
    "    # --------------------------------------------------------------------------\n",
    "    if any(np.where(survey==TSID)[0]):\n",
    "        sex_etc = survey[np.where(survey==TSID)[0][0]][3:8]\n",
    "        arr = np.repeat([sexDic[sex_etc[0]],\n",
    "                         int(sex_etc[1]), \n",
    "                         int(sex_etc[2]), \n",
    "                         int(sex_etc[3]),\n",
    "                         int(sex_etc[4][-2]),\n",
    "                         np.nan,\n",
    "                         np.nan,], \n",
    "                        10).reshape(arr.shape)\n",
    "\n",
    "    else:\n",
    "        sex_missing.append([TSID])\n",
    "        \n",
    "    # chonk, hair\n",
    "    # --------------------------------------------------------------------------\n",
    "    for BS, HV in itertools.product(BSs, HVs):\n",
    "        matches = getMatch('_meta_', fpTS, '_'+BS+'_', '_'+HV+'_', '.txt')\n",
    "        if matches:\n",
    "            x = re.split(\"_\", matches[0])\n",
    "            chonk, hair = np.genfromtxt(fpTS+'/'+matches[0], dtype='str', skip_header=True)[1:,1]\n",
    "            arr[-2:, 0, bsDic[x[1]], hvDic[x[2]]] = chonk, hair\n",
    "            \n",
    "        if not matches and getMatch('postmean', fpTS, '_'+BS+'_', '_'+HV+'_', '.npy'):\n",
    "            chonk_missing.append([TSID, BS, HV]) #f√ºr manuelles nachtragen\n",
    "    # --------------------------------------------------------------------------\n",
    "        #x[0]: TSID, x[1]: bs, x[2]: hv\n",
    "\n",
    "    da = xr.DataArray(\n",
    "        arr,\n",
    "        dims=['variableTSM', 'tsid', 'bs', 'hv'],\n",
    "        coords={'variableTSM':yStr,\n",
    "                'tsid':[TSID], 'bs':BSs, 'hv':['h', 'v']},\n",
    "        name='tsMeta'\n",
    "    )\n",
    "    da.to_netcdf(os.path.join(file_path_save, 'tsMeta', 'tsMeta'+TSID+'.nc'))\n",
    "    print(arr)\n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "if chonk_missing: raise Exception(f'CHONK AND HAIR MISSING FOR {chonk_missing}')\n",
    "if sex_missing: raise Exception(f'TS META MISSING FOR {sex_missing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f63be0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing tsMeta generator\n",
    "# =============================================================================\n",
    "for coords in chonk_missing:\n",
    "    matches = getMatch('_postmean_', os.path.join(file_path, coords[0]),\n",
    "                       coords[1]+'_', coords[2], '.npy')\n",
    "    timestamp = re.split(\"_\", matches[0])[-2]+'_'+ re.split(\"_\", matches[0])[-1][:-4]\n",
    "    \n",
    "    print(coords)\n",
    "    chonk = input('chonk: ')\n",
    "    hair = input('hair: ')\n",
    "    \n",
    "    with open(os.path.join(\n",
    "       file_path, coords[0], coords[0] +\"_\"+ coords[1] \n",
    "        + \"_\" + coords[2] +'_meta_'+timestamp+'.txt'), 'w') as f:\n",
    "       f.write(coords[0]+'\\n')\n",
    "       f.write(coords[1]+'  '+coords[2]+ '\\n\\n')\n",
    "       f.write('chonk: '+chonk)\n",
    "       f.write('\\n')\n",
    "       f.write('hair: '+hair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d5386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exMeta\n",
    "# =============================================================================\n",
    "\n",
    "yStr = ['timeStamp', 'burstMode', 'burstDuration', 'cre', 'ifc', 'mgn', 'khdwa']\n",
    "\n",
    "exMeta_missing = []\n",
    "for TSID in TSIDs:\n",
    "    fpTS = os.path.join(file_path, TSID)\n",
    "    arr = np.random.normal(size=(len(yStr),1,5,2))*np.nan\n",
    "\n",
    "    for BS, HV in itertools.product(BSs, HVs):\n",
    "        matches = getMatch('_exMeta_', fpTS, '_'+BS+'_', '_'+HV+'_', '.txt')\n",
    "        if matches:\n",
    "            x = re.split(\"_\", matches[0])\n",
    "            timeStamp, burstMode, burstDuration, cre, ifc, mgn, khdwa = np.genfromtxt(\n",
    "                fpTS+'/'+matches[0], dtype='str', skip_header=True)[1:,1]\n",
    "            arr[-2:, 0, bsDic[x[1]], hvDic[x[2]]] = chonk, hair\n",
    "        \n",
    "        checkMatch = getMatch('postmean', fpTS, '_'+BS+'_', '_'+HV+'_', '.npy')\n",
    "        if not matches and checkMatch:\n",
    "            exMeta_missing.append([TSID, BS, HV, \n",
    "                                   getTimestampFromStr(checkMatch[0][-20:-4])])\n",
    "    # --------------------------------------------------------------------------\n",
    "        #x[0]: TSID, x[1]: bs, x[2]: hv\n",
    "\n",
    "    da = xr.DataArray(\n",
    "        arr,\n",
    "        dims=['variableEXM', 'tsid', 'bs', 'hv'],\n",
    "        coords={'variableEXM':yStr,\n",
    "                'tsid':[TSID], 'bs':BSs, 'hv':['h', 'v']},\n",
    "        name='exMeta'\n",
    "    )\n",
    "    da.to_netcdf(os.path.join(file_path_save, 'exMeta', 'exMeta'+TSID+'.nc'))\n",
    "    \n",
    "if exMeta_missing: raise Exception(f'EXPERIMENT META MISSING FOR {exMeta_missing}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58f92f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing tsMeta generator\n",
    "# =============================================================================\n",
    "\n",
    "for coords in exMeta_missing:\n",
    "    matches = getMatch('_postmean_', os.path.join(file_path, coords[0]),\n",
    "                       coords[1]+'_', '_'+coords[2]+'_', '.npy')\n",
    "    timeStampStr = re.split(\"_\", matches[0])[-2]+'_'+ re.split(\"_\", matches[0])[-1][:-4]\n",
    "    \n",
    "    print(coords, timeStampStr)\n",
    "    timeStamp = coords[3]\n",
    "    burstMode = 0\n",
    "    burstDuration = 200\n",
    "    cre = 1\n",
    "    ifc = 1\n",
    "    mgn = input('mgn: ')\n",
    "    khdwa = input('khdwa: ')\n",
    "    \n",
    "    with open(os.path.join(\n",
    "    file_path, coords[0], coords[0] +\"_\"+ coords[1] \n",
    "     + \"_\" + coords[2] +'_exMeta_'+timeStampStr+'.txt'), 'w') as f:\n",
    "        f.write(coords[0]+'\\n')\n",
    "        f.write(coords[1]+'  '+coords[2]+ '\\n\\n')\n",
    "        f.write('timeStamp: '+str(timeStamp))\n",
    "        f.write('\\n')\n",
    "        f.write('burstMode: '+str(burstMode))\n",
    "        f.write('\\n')\n",
    "        f.write('burstDuration: '+str(burstDuration))\n",
    "        f.write('\\n')\n",
    "        f.write('cre: '+str(cre))\n",
    "        f.write('\\n')\n",
    "        f.write('ifc: '+str(ifc))\n",
    "        f.write('\\n')\n",
    "        f.write('mgn: '+str(mgn))\n",
    "        f.write('\\n')\n",
    "        f.write('khdwa: '+str(khdwa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07259e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
